# ai/routes/ai_chat.py
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Optional
from uuid import uuid4
from datetime import datetime
import logging

from ..service.rag import RAGService
from ..service.conversation import ConversationService
from ..service.ai_brain import ai_brain
from ..service.text_normalizer import text_normalizer
from ..service.tts_service import tts_service
from ..service.stt_service import stt_service
from ..service.query_understanding import QueryUnderstanding

logger = logging.getLogger(__name__)

try:
    from mongodb import db
except ImportError:
    from backend.mongodb import db

try:
    from ...security import require_expert
except ImportError:
    from security import require_expert

router = APIRouter(prefix="/ai", tags=["YINGRE AI"])


def _fix_mojibake(text: str) -> str:
    """Tente de corriger un texte mal d√©cod√© (ex: '√É¬©' -> '√©')."""
    if not text or not isinstance(text, str):
        return text

    if "√É" not in text:
        return text

    try:
        return text.encode("latin-1", errors="ignore").decode("utf-8", errors="ignore")
    except Exception:
        return text


def _rag_context_to_blocks(context_raw):
    """Normalise le contexte retourn√© par RAGService.ask() en liste de blocs.

    RAGService.ask() retourne actuellement un contexte texte o√π les documents sont
    s√©par√©s par "\n\n---\n\n" (souvent 'answers-only').
    Cette fonction g√®re aussi le cas o√π un ancien code renverrait une liste.
    """
    if not context_raw:
        return []

    # Compatibilit√© si un ancien code retourne une liste de strings
    if isinstance(context_raw, list):
        blocks = []
        for item in context_raw:
            if not item:
                continue
            if isinstance(item, str):
                blocks.extend([b.strip() for b in item.split("\n\n---\n\n") if b.strip()])
            else:
                blocks.append(str(item).strip())
        return [b for b in blocks if b]

    if isinstance(context_raw, str):
        return [b.strip() for b in context_raw.split("\n\n---\n\n") if b.strip()]

    return [str(context_raw).strip()]

# Initialiser les services
rag = RAGService()
conversation_service = ConversationService()

# ==============================
# Request Models
# ==============================
class ChatRequest(BaseModel):
    message: str
    session_id: Optional[str] = None
    category: Optional[str] = "general"  # Cat√©gorie par d√©faut
    language: Optional[str] = "fr"  # Langue choisie par l'utilisateur (fr, mo, di)


# ==============================
# Routes
# ==============================
@router.post("/chat")
def chat(req: ChatRequest, user=Depends(require_expert)):
    """
    Endpoint pour poser une question √† l'IA INTELLIGENTE.
    
    NOUVEAU: L'IA analyse, reformule et raisonne au lieu de copier-coller
    - D√©tecte la langue automatiquement
    - Reformule intelligemment avec un LLM (LLaMA 2 local)
    - Pose des questions de clarification si n√©cessaire
    - Guide l'utilisateur pas √† pas
    - Sauvegarde dans MongoDB avec session_id
    """
    try:
        # 1Ô∏è‚É£ D√©terminer la session
        session_id = req.session_id or str(uuid4())
        
        # 2Ô∏è‚É£ Utiliser la langue choisie par l'utilisateur (pas d'auto-d√©tection)
        detected_language = req.language or "fr"
        
        # 3Ô∏è‚É£ D√©tecter l'intent (salutation, question, remerciement)
        intent = conversation_service.detect_intent(req.message, detected_language)
        
        # 4Ô∏è‚É£ G√©rer les salutations et remerciements
        if intent == 'greeting':
            greeting_response = conversation_service.generate_greeting_response(detected_language)
            return {
                "session_id": session_id,
                "conversation_id": None,
                "question": req.message,
                "answer": greeting_response,
                "language": detected_language,
                "intent": intent,
                "context": [],
                "metadata": {"method": "greeting"}
            }
        
        if intent == 'thanks':
            thanks_response = conversation_service.generate_thanks_response(detected_language)
            return {
                "session_id": session_id,
                "conversation_id": None,
                "question": req.message,
                "answer": thanks_response,
                "language": detected_language,
                "intent": intent,
                "context": [],
                "metadata": {"method": "thanks"}
            }
        
        # 5Ô∏è‚É£ V√©rifier si on doit demander une clarification
        should_clarify, clarification = intelligent_chat.should_ask_clarification(
            req.message, detected_language
        )
        
        if should_clarify:
            return {
                "session_id": session_id,
                "conversation_id": None,
                "question": req.message,
                "answer": clarification,
                "language": detected_language,
                "intent": "clarification_needed",
                "context": [],
                "metadata": {"method": "clarification"}
            }

        # 6Ô∏è‚É£ R√©cup√©rer le contexte du RAG (multiple documents)
        answer_raw, context = rag.ask(req.message, k=5)  # Top 5 docs pertinents
        
        # 7Ô∏è‚É£ R√©cup√©rer l'historique de cette session
        history = []
        try:
            past_conversations = db.get_chat_conversations(user_id=user.get("id"))
            # Filtrer par session_id et prendre les 3 derniers
            history = [
                {"question": conv.get("question"), "answer": conv.get("answer")}
                for conv in past_conversations
                if conv.get("session_id") == session_id
            ][-3:]
        except:
            history = []
        
        # 8Ô∏è‚É£ üéØ G√âN√âRER UNE R√âPONSE INTELLIGENTE avec le LLM
        # PLUS de copier-coller ! L'IA analyse et reformule
        # RAGService.ask() renvoie un contexte texte (pas une liste)
        rag_context_full = context if isinstance(context, str) else ("\n\n".join(context) if context else "")
        
        intelligent_answer, metadata = intelligent_chat.generate_intelligent_response(
            question=req.message,
            rag_context=rag_context_full,
            language=detected_language,
            conversation_history=history
        )

        # 9Ô∏è‚É£ Sauvegarder dans MongoDB
        conversation_data = {
            "user_id": user.get("id"),
            "session_id": session_id,
            "category": req.category,
            "question": req.message,
            "answer": intelligent_answer,  # R√©ponse INTELLIGENTE, pas raw
            "context": context,
            "language": detected_language,
            "intent": intent,
            "metadata": metadata,  # Infos sur le LLM utilis√©
            "timestamp": datetime.utcnow()
        }

        conversation_id = db.save_chat_conversation(conversation_data)

        # üîü Retourner la r√©ponse intelligente
        return {
            "session_id": session_id,
            "conversation_id": conversation_id,
            "question": req.message,
            "answer": intelligent_answer,
            "language": detected_language,
            "intent": intent,
            "context": context,
            "metadata": metadata
        }

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Erreur du service AI: {str(e)}")


@router.get("/history")
def get_history(user=Depends(require_expert), session_id: Optional[str] = None, limit: int = 50):
    """
    R√©cup√®re l'historique des conversations pour un utilisateur ou une session
    """
    try:
        query = {"user_id": user.get("id")}
        if session_id:
            query["session_id"] = session_id

        conversations = db.get_chat_conversations(user_id=user.get("id"))
        return conversations[:limit]

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur r√©cup√©ration historique: {str(e)}")


@router.post("/chat/guest")
def chat_guest(req: ChatRequest):
    """
    Endpoint PUBLIC pour utilisateurs invit√©s (sans authentification).
    
    M√™me intelligence que /ai/chat mais sans besoin d'√™tre expert.
    - D√©tecte la langue automatiquement
    - Reformule intelligemment avec un LLM (LLaMA 2 local)
    - Pose des questions de clarification si n√©cessaire
    - Guide l'utilisateur pas √† pas
    """
    try:
        # 1Ô∏è‚É£ D√©terminer la session
        session_id = req.session_id or str(uuid4())
        
        # 2Ô∏è‚É£ D√©tecter la langue de la question
        detected_language = conversation_service.detect_language(req.message)
        
        # 3Ô∏è‚É£ D√©tecter l'intent (salutation, question, remerciement)
        try:
            intent = conversation_service.detect_intent(req.message, detected_language)
            logger.info(f"üéØ Intent d√©tect√©: {intent} pour '{req.message[:50]}'")
        except Exception as e:
            logger.error(f"‚ùå Erreur detect_intent: {e}")
            intent = "question"  # Par d√©faut
        
        # 4Ô∏è‚É£ G√©rer les salutations et remerciements (r√©ponses simples)
        if intent == "greeting":
            greetings = {
                "fr": "Bonjour ! Comment puis-je vous aider aujourd'hui ?",
                "mo": "K…©bare ! T√µnd nonglem maana yaa ?",
                "di": "I ni s…îg…îma ! N b…õ se ka i d…õm…õ di cogo jum…õn na ?"
            }
            return {
                "session_id": session_id,
                "conversation_id": None,
                "response": greetings.get(detected_language, greetings["fr"]),
                "language": detected_language,
                "intent": intent,
                "context": [],
                "timestamp": datetime.utcnow().isoformat()
            }
        
        if intent == "thanks":
            thanks_responses = {
                "fr": "Je vous en prie ! N'h√©sitez pas si vous avez d'autres questions.",
                "mo": "Barka ! K√£adem b s√£ y…©…© n k…©t y√µodo.",
                "di": "Baaraka ! Aw b…õna …≤ininkali w…õr…õw k…õ wa, i k'a f…î."
            }
            return {
                "session_id": session_id,
                "conversation_id": None,
                "response": thanks_responses.get(detected_language, thanks_responses["fr"]),
                "language": detected_language,
                "intent": intent,
                "context": [],
                "timestamp": datetime.utcnow().isoformat()
            }
        
        # 5Ô∏è‚É£ V√©rifier si on doit demander une clarification
        should_clarify, clarification = intelligent_chat.should_ask_clarification(
            req.message, detected_language
        )
        
        if should_clarify:
            return {
                "session_id": session_id,
                "conversation_id": None,
                "response": clarification,
                "language": detected_language,
                "intent": "clarification_needed",
                "context": [],
                "metadata": {"method": "clarification"},
                "timestamp": datetime.utcnow().isoformat()
            }

        # 6Ô∏è‚É£ R√©cup√©rer le contexte du RAG (multiple documents) FILTR√â par cat√©gorie
        logger.info(f"üîç Question: '{req.message}' | Langue: {detected_language} | Cat√©gorie re√ßue: '{req.category}'")
        logger.info(f"   Type de category: {type(req.category)} | Repr: {repr(req.category)}")
        answer_raw, context = rag.ask(
            query=req.message, 
            k=5,
            language=detected_language,
            category=req.category,  # üéØ FILTRAGE PAR CAT√âGORIE
            min_confidence=0.40  # üéØ Seuil de confiance (0.40 = √©quilibr√©)
        )
        
        # 7Ô∏è‚É£ Retourner directement la r√©ponse du RAG (logique pure, avec LLaMA 2)
        return {
            "session_id": session_id,
            "conversation_id": None,
            "response": answer_raw,  # R√©ponse directe du RAG
            "language": detected_language,
            "intent": intent,
            "context": context,
            "timestamp": datetime.utcnow().isoformat()
        }

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Erreur du service AI: {str(e)}")


@router.post("/chat/intelligent")
def chat_intelligent(req: ChatRequest):
    """
    üß† NOUVEAU: Endpoint avec IA VRAIMENT INTELLIGENTE
    
    Utilise Ollama (LLaMA 2 local) pour:
    - Analyser la question dans le contexte
    - Reformuler naturellement les r√©ponses RAG
    - Maintenir un dialogue coh√©rent
    - Adapter au contexte burkinab√®
    
    DIFF√âRENCE avec /chat/guest:
    - /chat/guest = RAG pur (copier-coller)
    - /chat/intelligent = RAG + LLM (dialogue intelligent)
    """
    try:
        # 1Ô∏è‚É£ NORMALISATION ET CORRECTION AUTOMATIQUE
        original_message = req.message
        normalized_message = text_normalizer.normalize(req.message)
        
        # Utiliser le message normalis√© pour le traitement
        req.message = normalized_message
        
        # Log si correction effectu√©e
        if normalized_message != original_message:
            logger.info(f"‚úèÔ∏è Message corrig√©: '{original_message}' ‚Üí '{normalized_message}'")
        
        # 2Ô∏è‚É£ Session management
        session_id = req.session_id or str(uuid4())
        
        # 3Ô∏è‚É£ Langue: prioriser le choix utilisateur (pas d'auto-d√©tection)
        detected_language = (req.language or "").strip() or "fr"
        
        try:
            intent = conversation_service.detect_intent(req.message, detected_language)
        except:
            intent = "question"
        
        # 4Ô∏è‚É£ D√âTECTER D√âCLARATIONS DE LANGUE (je parle fran√ßais/moore/dioula)
        message_lower = req.message.lower()
        language_declaration_keywords = [
            "je parle fran√ßais", "je parle francais", "je parque fran√ßais",
            "je parle moore", "je parle moor√©", "je parle mor√©",
            "je parle dioula", "je parle dyula",
            "en fran√ßais", "en francais", "parle fran√ßais"
        ]
        
        if any(keyword in message_lower for keyword in language_declaration_keywords):
            language_response = (
                "D'accord. Je te r√©ponds en fran√ßais.\n\n"
                "Pose-moi ta question (ex: plantes m√©dicinales, karit√©/PFNL, savon, m√©tiers, civisme, maths pratiques)."
            )
            
            ai_brain.add_to_history("user", req.message)
            ai_brain.add_to_history("assistant", language_response)
            
            return {
                "session_id": session_id,
                "response": language_response,
                "language": "fr",
                "intent": "language_declaration",
                "mode": "language_preference",
                "timestamp": datetime.utcnow().isoformat()
            }
        
        # 5Ô∏è‚É£ D√âTECTER DEMANDES D'EXEMPLES (montre-moi, donne exemple, je choisis)
        example_keywords = [
            "montre", "montre moi", "montre-moi", "exemple", "exemples",
            "donne exemple", "donne-moi exemple", "cite", "liste",
            "je choisis", "j'ai choisi", "je veux", "je voudrais",
            "parle moi de", "parle-moi de", "dis moi", "dis-moi"
        ]
        
        # D√©tecter le domaine mentionn√©
        domain_keywords = {
            "plantes": "Plantes Medicinales",
            "plante": "Plantes Medicinales",
            "m√©dicinale": "Plantes Medicinales",
            "medicinale": "Plantes Medicinales",
            "rem√®de": "Plantes Medicinales",
            "remede": "Plantes Medicinales",
            "sant√©": "Plantes Medicinales",
            "sante": "Plantes Medicinales",
            "maladie": "Plantes Medicinales",
            
            "agriculture": "Agriculture Locale",
            "cultiver": "Agriculture Locale",
            "culture": "Agriculture Locale",
            "mil": "Agriculture Locale",
            "sorgho": "Agriculture Locale",
            
            "savon": "Science Pratique - Saponification",
            "saponification": "Science Pratique - Saponification",
            
            "m√©tier": "Metiers Informels",
            "metier": "Metiers Informels",
            "business": "Metiers Informels",
        }
        
        is_asking_example = any(keyword in message_lower for keyword in example_keywords)
        detected_domain = None
        
        for keyword, domain in domain_keywords.items():
            if keyword in message_lower:
                detected_domain = domain
                break
        
        # Si pas de domaine d√©tect√© mais demande d'exemple, utiliser la cat√©gorie fournie
        if is_asking_example and not detected_domain:
            if req.category and req.category != "general":
                detected_domain = req.category
        
        # Si demande d'exemples + domaine d√©tect√© ‚Üí Donner des exemples concrets
        if is_asking_example and detected_domain:
            # Exemples pr√©-d√©finis par domaine
            domain_examples = {
                "Plantes Medicinales": (
                    "üåø **Voici des plantes m√©dicinales burkinab√® que je connais:**\n\n"
                    "1. **Moringa** üå± - Combat la fatigue et l'an√©mie\n"
                    "   ‚Üí Consommer 1 cuill√®re √† soupe de poudre par jour\n\n"
                    "2. **Karit√©** ü•ú - Soins de la peau et cheveux\n"
                    "   ‚Üí Beurre naturel pour hydrater et prot√©ger\n\n"
                    "3. **Baobab** üå≥ - Riche en vitamine C\n"
                    "   ‚Üí Poudre de fruit pour renforcer l'immunit√©\n\n"
                    "4. **N√©r√©** üå∞ - Soumbala pour l'assaisonnement\n"
                    "   ‚Üí Aide la digestion et riche en prot√©ines\n\n"
                    "**Pose-moi une question pr√©cise sur une plante !**\n"
                    "Exemple: \"Comment utiliser le moringa contre la fatigue ?\""
                ),
                "Agriculture Locale": (
                    "üåæ **Voici des cultures importantes au Burkina Faso:**\n\n"
                    "1. **Mil** - Culture vivri√®re de base\n"
                    "   ‚Üí Planter en d√©but de saison des pluies\n\n"
                    "2. **Sorgho** - R√©sistant √† la s√©cheresse\n"
                    "   ‚Üí Bon pour le t√¥ et le dolo\n\n"
                    "3. **Ma√Øs** - Culture commerciale\n"
                    "   ‚Üí Demande plus d'eau\n\n"
                    "4. **Ni√©b√© (haricot)** - Prot√©ines v√©g√©tales\n"
                    "   ‚Üí Enrichit le sol en azote\n\n"
                    "**Pose une question pr√©cise !**\n"
                    "Exemple: \"Quelle est la meilleure p√©riode pour cultiver le mil ?\""
                ),
                "Science Pratique - Saponification": (
                    "üß¥ **Je peux t'aider avec la fabrication de savon:**\n\n"
                    "- Savon √† base de karit√©\n"
                    "- Savon noir traditionnel\n"
                    "- Saponification √† froid\n"
                    "- Dosage de la soude caustique\n\n"
                    "**Pose une question !**\n"
                    "Exemple: \"Comment faire du savon au karit√© ?\""
                ),
                "Metiers Informels": (
                    "üíº **Voici des m√©tiers informels au Burkina:**\n\n"
                    "- Transformation de produits locaux\n"
                    "- Petit commerce\n"
                    "- Artisanat\n"
                    "- Services √† domicile\n\n"
                    "**Dis-moi ce qui t'int√©resse !**"
                )
            }
            
            example_response = domain_examples.get(
                detected_domain,
                f"Je peux t'aider avec {detected_domain}. Pose-moi une question pr√©cise !"
            )
            
            ai_brain.add_to_history("user", req.message)
            ai_brain.add_to_history("assistant", example_response)
            
            return {
                "session_id": session_id,
                "response": example_response,
                "language": detected_language,
                "intent": "request_examples",
                "mode": "examples_provided",
                "category": detected_domain,
                "timestamp": datetime.utcnow().isoformat()
            }
        
        # 6Ô∏è‚É£ D√âTECTER QUESTIONS DE PR√âSENTATION (qui/nom/appelles)
        presentation_keywords = [
            "comment tu t'appel", "comment t'appel", "tu t'appel", 
            "c'est quoi ton nom", "quel est ton nom", "ton nom",
            "qui es tu", "qui es-tu", "tu es qui", "t'es qui",
            "comment tu", "qui tu es"
        ]
        
        if any(keyword in message_lower for keyword in presentation_keywords):
            presentation_response = (
                "Je m'appelle YINGR-AI ! üáßüá´\n\n"
                "Je suis l'Intelligence Artificielle locale et souveraine du Burkina Faso. "
                "Mon r√¥le est de t'aider avec des connaissances pratiques sur:\n"
                "‚Ä¢ Les plantes m√©dicinales üåø\n"
                "‚Ä¢ L'agriculture locale üåæ\n"
                "‚Ä¢ La transformation de produits üß¥\n"
                "‚Ä¢ Les m√©tiers informels üíº\n"
                "‚Ä¢ Le civisme et le d√©veloppement personnel üìö\n\n"
                "Comment puis-je t'aider aujourd'hui ?"
            )
            
            ai_brain.add_to_history("user", req.message)
            ai_brain.add_to_history("assistant", presentation_response)
            
            return {
                "session_id": session_id,
                "response": presentation_response,
                "language": detected_language,
                "intent": "presentation",
                "mode": "intelligent_presentation",
                "timestamp": datetime.utcnow().isoformat()
            }
        
        # 7Ô∏è‚É£ G√©rer salutations (SANS LLM pour r√©ponses plus rapides et consistantes)
        if intent == "greeting":
            greeting_responses_fr = [
                "Bonjour ! Je suis YINGR-AI, ton assistant burkinab√®. üáßüá´\n\nComment puis-je t'aider aujourd'hui ?",
                "Salut ! Content de te parler. üòä\n\nQue veux-tu savoir ?",
                "Bienvenue ! Je suis l√† pour t'aider. üëã\n\nPose-moi tes questions sur l'agriculture, la sant√©, les m√©tiers..."
            ]
            
            import random
            greeting_response = random.choice(greeting_responses_fr)
            
            ai_brain.add_to_history("user", req.message)
            ai_brain.add_to_history("assistant", greeting_response)
            
            return {
                "session_id": session_id,
                "response": greeting_response,
                "language": detected_language,
                "intent": intent,
                "mode": "intelligent_greeting",
                "timestamp": datetime.utcnow().isoformat()
            }
        
        # 8Ô∏è‚É£ G√©rer remerciements (SANS LLM pour r√©ponses plus rapides)
        if intent == "thanks":
            thanks_responses_fr = [
                "Je t'en prie ! üòä N'h√©site pas si tu as d'autres questions.",
                "Avec plaisir ! Je suis l√† pour t'aider. üôå",
                "Pas de souci ! Reviens quand tu veux. üëç"
            ]
            
            import random
            thanks_response = random.choice(thanks_responses_fr)
            
            ai_brain.add_to_history("user", req.message)
            ai_brain.add_to_history("assistant", thanks_response)
            
            return {
                "session_id": session_id,
                "response": thanks_response,
                "language": detected_language,
                "intent": intent,
                "mode": "intelligent_thanks",
                "timestamp": datetime.utcnow().isoformat()
            }
        
        # 9Ô∏è‚É£ COMPRENDRE L'INTENTION de la question
        logger.info(f"üß† Question originale: '{req.message}'")
        
        # Essayer de comprendre la question (surtout pour sant√©)
        understanding = QueryUnderstanding.understand_health_query(req.message)
        if understanding:
            logger.info(f"üí° Compr√©hension: {understanding['suggestion']}")
            # Utiliser la requ√™te reformul√©e
            expanded_query = understanding['reformulated_query']
        else:
            # Enrichir la question avec des mots-cl√©s et synonymes
            expanded_query = req.message
            
            # Ajouter des mots-cl√©s selon le contexte
            query_lower = req.message.lower()
            
            # Probl√®mes digestifs (estomac, gaz, ballonnement, digestion...)
            if any(word in query_lower for word in ['maux', 'mal', 'douleur', 'soigner', 'traiter', 'estomac', 'ventre', 'gaz', 'ballonnement', 'digestion', 'intestin', 'gastrique']):
                # Ajouter des termes m√©dicaux locaux + synonymes
                expanded_query += " plantes m√©dicinales traditionnelles Burkina traitement naturel rem√®de estomac ventre digestion gastrique"
            
            # Fabrication savon
            elif any(word in query_lower for word in ['savon', 'fabriquer', 'saponification', 'lessive']):
                expanded_query += " fabrication artisanale transformation saponification recette savon"
            
            # Karit√© et PFNL
            elif any(word in query_lower for word in ['karit√©', 'beurre', 'noix', 'pfnl']):
                expanded_query += " transformation PFNL beurre karit√© production artisanale"
            
            # Maladies et sympt√¥mes g√©n√©raux
            elif any(word in query_lower for word in ['fi√®vre', 'toux', 'rhume', 'paludisme', 'malade']):
                expanded_query += " plantes m√©dicinales sant√© traitement naturel Burkina rem√®de"
        
        logger.info(f"üîç Question enrichie: '{expanded_query}'")
        
        # Interroger le RAG avec la requ√™te enrichie
        answer_raw, context_raw = rag.ask(
            query=expanded_query,  # ‚Üê Utiliser la requ√™te ENRICHIE
            k=10,
            language=detected_language,
            category=req.category,
            min_confidence=0.15
        )
        
        logger.info(f"üìä RAG r√©sultats: answer_raw length={len(answer_raw) if answer_raw else 0}, context_raw length={len(context_raw) if context_raw else 0}")
        if isinstance(context_raw, str):
            logger.info(f"üìÑ Contexte brut (100 premiers chars): {context_raw[:100] if context_raw else 'VIDE'}")
        else:
            logger.info(f"üìÑ Contexte brut (type={type(context_raw)}): {str(context_raw)[:100] if context_raw else 'VIDE'}")
        
        # 9Ô∏è‚É£ Transformer le contexte en format adapt√© pour AI Brain
        # RAGService.ask() renvoie un contexte texte avec s√©parateur "\n\n---\n\n".
        # Ce contexte est souvent "answers-only" (sans questions), donc on construit
        # des pseudo-sources Q/R en r√©utilisant la question utilisateur.
        rag_results = []
        for block in _rag_context_to_blocks(context_raw)[:3]:
            rag_results.append({
                "question": req.message,
                "reponse": block
            })
        
        logger.info(f"üìö {len(rag_results)} documents structur√©s pour le LLM")
        
        # üîü üéØ G√âN√âRATION INTELLIGENTE avec AI Brain
        intelligent_response = ai_brain.generate_intelligent_response(
            question=req.message,
            rag_results=rag_results,
            category=req.category,
            language=detected_language
        )
        
        # 1Ô∏è‚É£1Ô∏è‚É£ üîä G√âN√âRATION AUDIO (uniquement pour moor√© et dioula)
        audio_url = None
        audio_mode = "not_available"
        
        if detected_language in ["mo", "di"]:  # Moor√© ou Dioula
            try:
                response_text = intelligent_response["reponse"]
                audio_url, audio_mode = tts_service.generate_audio(
                    text=response_text,
                    language=detected_language
                )
                logger.info(f"üîä Audio g√©n√©r√©: {audio_url} (mode: {audio_mode})")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Audio non disponible: {e}")
                audio_url = None
                audio_mode = "not_available"
        
        # 1Ô∏è‚É£2Ô∏è‚É£ Retourner la r√©ponse intelligente avec audio
        response_text = _fix_mojibake(intelligent_response["reponse"])
        context_first = _fix_mojibake(rag_results[0]["reponse"]) if rag_results else ""

        payload = {
            "session_id": session_id,
            "response": response_text,
            "language": detected_language,
            "intent": intent,
            "category": intelligent_response["categorie"],
            "sources_count": intelligent_response.get("sources_utilisees", 0),
            "mode": intelligent_response.get("mode", "intelligent"),
            "context": [context_first] if context_first else [],  # Premi√®re source
            "timestamp": intelligent_response.get("timestamp", datetime.utcnow().isoformat()),
            "audio_url": audio_url,
            "audio_mode": audio_mode
        }

        # Certains clients (ex: PowerShell Invoke-WebRequest) affichent des accents cass√©s
        # si le charset n'est pas pr√©cis√©. On force UTF-8 pour un rendu correct.
        return JSONResponse(content=payload, media_type="application/json; charset=utf-8")
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        logger.error(f"‚ùå Erreur chat intelligent: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur service AI intelligent: {str(e)}")


@router.post("/chat/clear-history")
def clear_chat_history():
    """Efface l'historique conversationnel (pour tests)"""
    try:
        ai_brain.clear_history()
        return {"status": "ok", "message": "Historique effac√©"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/chat/voice")
async def chat_voice(
    audio: UploadFile = File(...),
    session_id: Optional[str] = None,
    category: Optional[str] = "general",
    language: Optional[str] = "fr"  # Langue choisie par l'utilisateur
):
    """
    Endpoint pour envoyer un message VOCAL (Speech-to-Text puis dialogue intelligent)
    
    Flux complet: Audio ‚Üí STT (Whisper) ‚Üí Texte ‚Üí RAG+LLM ‚Üí Texte ‚Üí TTS ‚Üí Audio
    
    Permet aux utilisateurs de parler en moor√©/dioula sans taper les caract√®res sp√©ciaux (…î, …õ, etc.)
    """
    try:
        logger.info("=" * 60)
        logger.info("üé§ NOUVELLE REQU√äTE VOCALE")
        logger.info("=" * 60)
        
        # 1Ô∏è‚É£ V√©rifier que STT est disponible
        if not stt_service.is_available():
            logger.error("‚ùå Service STT non disponible")
            raise HTTPException(
                status_code=503,
                detail="Service de reconnaissance vocale non disponible. Installer Whisper: pip install openai-whisper"
            )
        
        logger.info("‚úÖ Service STT disponible")
        
        # 2Ô∏è‚É£ Lire les donn√©es audio
        logger.info(f"üì• R√©ception audio: {audio.filename} ({audio.content_type})")
        audio_bytes = await audio.read()
        logger.info(f"üìä Taille audio: {len(audio_bytes)} bytes ({len(audio_bytes)/1024:.1f} KB)")
        
        if len(audio_bytes) == 0:
            logger.error("‚ùå Fichier audio vide")
            raise HTTPException(status_code=400, detail="Fichier audio vide")
        
        if len(audio_bytes) < 1000:  # Moins de 1KB = probablement invalide
            logger.warning(f"‚ö†Ô∏è Audio tr√®s court: {len(audio_bytes)} bytes")
        
        # 3Ô∏è‚É£ Transcription Speech-to-Text avec Whisper
        logger.info(f"üîÑ Lancement transcription Whisper (langue: {language})...")
        
        try:
            # Utiliser la langue choisie par l'utilisateur au lieu de l'auto-d√©tection
            transcription, detected_language, confidence = stt_service.transcribe_audio_bytes(
                audio_bytes=audio_bytes,
                filename=audio.filename,
                language=language  # Utiliser la langue choisie
            )
        except Exception as e:
            logger.error(f"‚ùå Erreur transcription Whisper: {e}")
            import traceback
            traceback.print_exc()
            raise HTTPException(
                status_code=500,
                detail=f"Erreur lors de la transcription: {str(e)}"
            )
        
        logger.info(f"üìù Transcription brute: '{transcription}' (longueur: {len(transcription)})")

        # Si Whisper n'a rien compris, renvoyer une r√©ponse gentille plut√¥t qu'une erreur 400
        if not transcription or len(transcription.strip()) == 0:
            logger.error("‚ùå Transcription vide, Whisper n'a rien compris")
            return {
                "session_id": session_id or f"voice_{uuid4().hex[:8]}",
                "transcription": "",
                "transcription_confidence": 0.0,
                "response": (
                    "Je n'ai pas bien entendu ce que tu as dit. "
                    "Peux-tu r√©p√©ter en parlant un peu plus fort et pendant 3 √† 5 secondes ?"
                ),
                "language": language or "fr",
                "intent": "incomprehensible_audio",
                "category": category or "general",
                "sources_count": 0,
                "mode": "voice_intelligent",
                "context": [],
                "audio_url": None,
                "audio_mode": "not_available",
            }

        logger.info(f"‚úÖ Transcription r√©ussie: '{transcription}' (langue: {detected_language}, confiance: {confidence:.2%})")
        
        # 4Ô∏è‚É£ Traiter le texte transcrit avec l'endpoint intelligent
        # Utiliser le m√™me flux que /chat/intelligent
        
        # Cr√©er une requ√™te interne
        from pydantic import BaseModel
        
        class InternalChatRequest(BaseModel):
            message: str
            session_id: Optional[str] = None
            category: Optional[str] = "general"
        
        internal_req = InternalChatRequest(
            message=transcription,
            session_id=session_id,
            category=category,
            language=language  # Utiliser la langue choisie
        )
        
        # 5Ô∏è‚É£ Appeler la logique du chat intelligent
        # (On r√©utilise le m√™me code que /chat/intelligent)
        
        # G√©n√©rer session_id si n√©cessaire
        if not session_id:
            session_id = f"voice_{uuid4().hex[:8]}"
        
        # Normaliser le texte (correction typos)
        normalized_message = text_normalizer.normalize(transcription)
        logger.info(f"üìù Message normalis√©: '{normalized_message}'")

        # Utiliser la langue choisie par l'utilisateur (pas d'auto-d√©tection)
        detected_lang = language
        intent = conversation_service.detect_intent(normalized_message, detected_lang)

        # üìå Cas sp√©cial : salutations vocales
        if intent == "greeting":
            logger.info("üôã Intent vocal d√©tect√©: greeting ‚Äì r√©ponse d'accueil sans RAG")

            greeting_text = conversation_service.generate_greeting_response(detected_lang)

            audio_url = None
            audio_mode = "not_available"
            if detected_lang in ["mo", "di"]:
                try:
                    audio_url, audio_mode = tts_service.generate_audio(
                        text=greeting_text,
                        language=detected_lang
                    )
                    logger.info(f"üîä Audio r√©ponse greeting g√©n√©r√©: {audio_url} (mode: {audio_mode})")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Audio r√©ponse greeting non disponible: {e}")

            return {
                "session_id": session_id,
                "transcription": transcription,
                "transcription_confidence": confidence,
                "response": greeting_text,
                "language": detected_lang,
                "intent": intent,
                "category": category,
                "sources_count": 0,
                "mode": "voice_greeting",
                "context": [],
                "timestamp": datetime.utcnow().isoformat(),
                "audio_url": audio_url,
                "audio_mode": audio_mode,
                "stt_service": "whisper",
                "workflow": "voice ‚Üí stt ‚Üí greeting"
            }

        # Interroger RAG pour les autres intents
        answer_raw, context_raw = rag.ask(
            query=normalized_message,
            k=3,
            language=detected_lang,
            category=category,
            min_confidence=0.35
        )

        # Transformer contexte RAG
        rag_results = []
        for block in _rag_context_to_blocks(context_raw)[:3]:
            rag_results.append({
                "question": normalized_message,
                "reponse": block
            })

        # G√©n√©ration intelligente avec AI Brain
        intelligent_response = ai_brain.generate_intelligent_response(
            question=normalized_message,
            rag_results=rag_results,
            category=category,
            language=detected_lang
        )
        
        # 6Ô∏è‚É£ G√©n√©ration audio de la r√©ponse (TTS)
        audio_url = None
        audio_mode = "not_available"
        
        if detected_lang in ["mo", "di"]:
            try:
                response_text = intelligent_response["reponse"]
                audio_url, audio_mode = tts_service.generate_audio(
                    text=response_text,
                    language=detected_lang
                )
                logger.info(f"üîä Audio r√©ponse g√©n√©r√©: {audio_url} (mode: {audio_mode})")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Audio r√©ponse non disponible: {e}")
        
        # 7Ô∏è‚É£ Retourner la r√©ponse compl√®te
        return {
            "session_id": session_id,
            "transcription": transcription,  # ‚Üê Texte transcrit
            "transcription_confidence": confidence,
            "response": intelligent_response["reponse"],
            "language": detected_lang,
            "intent": intent,
            "category": intelligent_response["categorie"],
            "sources_count": intelligent_response.get("sources_utilisees", 0),
            "mode": "voice_intelligent",  # Mode sp√©cial pour voix
            "context": [rag_results[0]["reponse"]] if rag_results else [],
            "timestamp": intelligent_response.get("timestamp", datetime.utcnow().isoformat()),
            "audio_url": audio_url,  # ‚Üê Audio de la r√©ponse
            "audio_mode": audio_mode,
            "stt_service": "whisper",
            "workflow": "voice ‚Üí stt ‚Üí rag+llm ‚Üí tts ‚Üí voice"
        }
    
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        logger.error(f"‚ùå Erreur chat vocal: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur service chat vocal: {str(e)}")

